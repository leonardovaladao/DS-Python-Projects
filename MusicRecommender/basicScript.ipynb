{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f476acd4",
   "metadata": {},
   "source": [
    "# Music Recommender with AudioScrobbler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05a43347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-KMS1OBO:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>MusicRecommender</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x21afcff1340>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "spark = (pyspark\n",
    "         .sql\n",
    "         .SparkSession.builder\n",
    "         .master(\"local[*]\")\n",
    "         .appName(\"MusicRecommender\")\n",
    "         .config(\"spark.driver.memory\", \"4g\") # Main methods, organize lazy actions\n",
    "         .config(\"spark.executor.memory\", \"8g\") # Nodes, execute transformations\n",
    "         .getOrCreate())\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba1ea83",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16289ba0",
   "metadata": {},
   "source": [
    "Data can be obtained in: http://www-ens.iro.umontreal.ca/~bergstrj/audioscrobbler_data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143dc744",
   "metadata": {},
   "source": [
    "Audioscrobbler dataset with:\n",
    "- user_artist_data.txt: 141K unique users, 1.6M unique artists, 24M datapoints.\n",
    "- artist_data.txt: 1.8M datapoints\n",
    "- artist_alias.txt: 193K datapoints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93023872",
   "metadata": {},
   "source": [
    "#### Take raw datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d3b5b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|              value|\n",
      "+-------------------+\n",
      "|       1000002 1 55|\n",
      "| 1000002 1000006 33|\n",
      "|  1000002 1000007 8|\n",
      "|1000002 1000009 144|\n",
      "|1000002 1000010 314|\n",
      "+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rawUserArtistData = spark.read.text(\"ds/user_artist_data.txt\")\n",
    "rawUserArtistData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24710f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------+\n",
      "|value                                |\n",
      "+-------------------------------------+\n",
      "|1134999\t06Crazy Life                 |\n",
      "|6821360\tPang Nakarin                 |\n",
      "|10113088\tTerfel, Bartoli- Mozart: Don|\n",
      "|10151459\tThe Flaming Sidebur         |\n",
      "|6826647\tBodenstandig 3000            |\n",
      "+-------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rawArtistData = spark.read.text(\"ds/artist_data.txt\")\n",
    "rawArtistData.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d453dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|           value|\n",
      "+----------------+\n",
      "| 1092764\t1000311|\n",
      "| 1095122\t1000557|\n",
      "| 6708070\t1007267|\n",
      "|10088054\t1042317|\n",
      "| 1195917\t1042317|\n",
      "+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rawArtistAlias = spark.read.text(\"ds/artist_alias.txt\")\n",
    "rawArtistAlias.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84bdb6d",
   "metadata": {},
   "source": [
    "#### Organize raw DataFrames intro structured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acfff4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+\n",
      "| userid|artistid|playcount|\n",
      "+-------+--------+---------+\n",
      "|1000002|       1|       55|\n",
      "|1000002| 1000006|       33|\n",
      "|1000002| 1000007|        8|\n",
      "|1000002| 1000009|      144|\n",
      "|1000002| 1000010|      314|\n",
      "+-------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as f\n",
    "split_col = f.split(rawUserArtistData.value, ' ')\n",
    "\n",
    "userArtistDF = (rawUserArtistData.withColumn('userid', split_col.getItem(0))\n",
    ".withColumn('artistid', split_col.getItem(1))\n",
    ".withColumn('playcount', split_col.getItem(2))\n",
    ".drop(rawUserArtistData.value)\n",
    "               )\n",
    "\n",
    "userArtistDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48e142e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------------------+\n",
      "|artistid|artist_name                 |\n",
      "+--------+----------------------------+\n",
      "|1134999 |06Crazy Life                |\n",
      "|6821360 |Pang Nakarin                |\n",
      "|10113088|Terfel, Bartoli- Mozart: Don|\n",
      "|10151459|The Flaming Sidebur         |\n",
      "|6826647 |Bodenstandig 3000           |\n",
      "+--------+----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "split_col = f.split(rawArtistData.value, '\\t')\n",
    "\n",
    "artistData = (rawArtistData\n",
    ".withColumn(\"artistid\", split_col.getItem(0))\n",
    ".withColumn(\"artist_name\", split_col.getItem(1))\n",
    ".drop(\"value\"))\n",
    "\n",
    "artistData.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe1beb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|badid   |goodid |\n",
      "+--------+-------+\n",
      "|1092764 |1000311|\n",
      "|1095122 |1000557|\n",
      "|6708070 |1007267|\n",
      "|10088054|1042317|\n",
      "|1195917 |1042317|\n",
      "+--------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "split_col = f.split(rawArtistAlias.value, '\\t')\n",
    "\n",
    "artistAlias = (rawArtistAlias\n",
    "               .withColumn(\"badid\", split_col.getItem(0))\n",
    "               .withColumn(\"goodid\", split_col.getItem(1))\n",
    "               .drop(\"value\")\n",
    ")\n",
    "\n",
    "artistAlias.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "375c4883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+\n",
      "|artistid|   artist_name|\n",
      "+--------+--------------+\n",
      "| 1000311| Steve Winwood|\n",
      "| 1092764|Winwood, Steve|\n",
      "+--------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artistData.filter(artistData.artistid.isin(\"1092764\", \"1000311\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ee07e6",
   "metadata": {},
   "source": [
    "### On average, how many artists an individual user listen to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "015bc4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|Average Artists per User|\n",
      "+------------------------+\n",
      "|      164.04492576513562|\n",
      "+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count,avg\n",
    "userArtistDF.groupBy(\"userid\").agg(count(\"artistid\").alias(\"artistCount\")).agg(avg(\"artistCount\").\n",
    "                                                                               alias(\"Average Artists per User\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bb3e34",
   "metadata": {},
   "source": [
    "### Use Alias to create a canonical Id for artists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15626b7f",
   "metadata": {},
   "source": [
    "Use join to see single artist's names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddbe0251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------+\n",
      "|   artist_name| goodid|\n",
      "+--------------+-------+\n",
      "|          Cher|1000280|\n",
      "| Dead Or Alive|1000795|\n",
      "|Rimini Project|1000839|\n",
      "|  Stevie Nicks|1001866|\n",
      "|        Digger|1002783|\n",
      "+--------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col \n",
    "canArtistData = (artistData\n",
    " .alias(\"a1\")\n",
    " .join(artistAlias.alias(\"id\"), on=[col(\"a1.artistid\")==col(\"id.badid\")], how=\"left\")\n",
    " .join(artistData.alias(\"a2\"), on=col(\"a2.artistid\")==col(\"id.goodid\"), how=\"left\")\n",
    " .select(\"a2.artist_name\", \"id.goodid\")\n",
    " .distinct()\n",
    ")\n",
    "canArtistData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28d09f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many unique artists there are?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22475"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"How many unique artists there are?\")\n",
    "canArtistData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6079dce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there misspelled Id's on the userArtistDF?\n",
      "+-------+--------+---------+-------+-------+\n",
      "| userid|artistid|playcount|  badid| goodid|\n",
      "+-------+--------+---------+-------+-------+\n",
      "|1000002| 1000434|       89|1000434|1000518|\n",
      "|1000002| 1000762|        1|1000762|1001514|\n",
      "|1000002| 1001220|        1|1001220|    721|\n",
      "|1000002| 1001410|        5|1001410|1034635|\n",
      "|1000002| 1002498|        1|1002498|   3066|\n",
      "|1000002| 1003377|        1|1003377|6691692|\n",
      "|1000002| 1003633|        1|1003633|1237611|\n",
      "|1000002| 1006102|        4|1006102|1034635|\n",
      "|1000002| 1007652|        1|1007652|1001172|\n",
      "|1000002| 1010219|        2|1010219|1008391|\n",
      "+-------+--------+---------+-------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Is there misspelled Id's on the userArtistDF?\")\n",
    "(userArtistDF\n",
    " .join(artistAlias, \n",
    "      on= (userArtistDF.artistid==artistAlias.badid),\n",
    "      how=\"inner\")\n",
    "\n",
    ").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d093f1",
   "metadata": {},
   "source": [
    "In the above DF, the same *(userid, artistid)* pair may have multiple rows because of mispelled Id."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcad5ef",
   "metadata": {},
   "source": [
    "#### Create a cannonical userArtistDF which will be the trainData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff42ffc1",
   "metadata": {},
   "source": [
    "Create a Python Dictionary which will map each Id (being *badid* or *goodid*) to the cannonical Id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8acc27c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapIds = {}\n",
    "mapIds.update(\n",
    "    {row['badid']:row['goodid'] for row in artistAlias.collect()}\n",
    ")\n",
    "mapIds.update(\n",
    "    {row['goodid']:row['goodid'] for row in artistAlias.collect()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3835c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+\n",
      "| userid|artistid|playcount|\n",
      "+-------+--------+---------+\n",
      "|1000002|       1|       55|\n",
      "|1000002| 1000006|       33|\n",
      "|1000002| 1000007|        8|\n",
      "|1000002| 1000009|      144|\n",
      "|1000002| 1000010|      314|\n",
      "|1000002| 1000013|        8|\n",
      "|1000002| 1000014|       42|\n",
      "|1000002| 1000017|       69|\n",
      "|1000002| 1000024|      329|\n",
      "|1000002| 1000025|        1|\n",
      "|1000002| 1000028|       17|\n",
      "|1000002| 1000031|       47|\n",
      "|1000002| 1000033|       15|\n",
      "|1000002| 1000042|        1|\n",
      "|1000002| 1000045|        1|\n",
      "|1000002| 1000054|        2|\n",
      "|1000002| 1000055|       25|\n",
      "|1000002| 1000056|        4|\n",
      "|1000002| 1000059|        2|\n",
      "|1000002| 1000062|       71|\n",
      "+-------+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "canUserArtistDF = (userArtistDF\n",
    " .rdd\n",
    " .map(lambda x: (x[0], mapIds.get(x[1], x[1]), x[2]))\n",
    " .toDF([\"userid\", \"artistid\", \"playcount\"])\n",
    ")\n",
    "\n",
    "canUserArtistDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be05bcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b13d6fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "canUserArtistDfToSave = (canUserArtistDF\n",
    "                         .select(\n",
    "                             concat(\n",
    "                                 canUserArtistDF.userid, \n",
    "                                 lit(\" \"),\n",
    "                                 canUserArtistDF.artistid, \n",
    "                                 lit(\" \"), \n",
    "                                 canUserArtistDF.playcount)\n",
    "                             .alias(\"value\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5aad07f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(canUserArtistDfToSave\n",
    " .repartition(10)\n",
    " .write\n",
    " .format(\"text\")\n",
    " .option(\"header\", \"false\")\n",
    " .mode(\"overwrite\")\n",
    " .save(\"./testData2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dddec98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|              value|\n",
      "+-------------------+\n",
      "|       1000002 1 55|\n",
      "| 1000002 1000006 33|\n",
      "|  1000002 1000007 8|\n",
      "|1000002 1000009 144|\n",
      "|1000002 1000010 314|\n",
      "|  1000002 1000013 8|\n",
      "| 1000002 1000014 42|\n",
      "| 1000002 1000017 69|\n",
      "|1000002 1000024 329|\n",
      "|  1000002 1000025 1|\n",
      "| 1000002 1000028 17|\n",
      "| 1000002 1000031 47|\n",
      "| 1000002 1000033 15|\n",
      "|  1000002 1000042 1|\n",
      "|  1000002 1000045 1|\n",
      "|  1000002 1000054 2|\n",
      "| 1000002 1000055 25|\n",
      "|  1000002 1000056 4|\n",
      "|  1000002 1000059 2|\n",
      "| 1000002 1000062 71|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testWith1Column.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7d227c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391823c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0f94ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.filter(col(\"_2\")==\"1000006\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "46e65962",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'Column'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25556/6739900.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m (userArtistDF\n\u001b[1;32m----> 2\u001b[1;33m  \u001b[1;33m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"realid\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmapArtistAlias\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"artistid\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m ).show()\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'Column'"
     ]
    }
   ],
   "source": [
    "(userArtistDF\n",
    " .withColumn(\"realid\", map)\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f320b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7ddcec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377a50d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11496297",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ff5355f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\apps\\opt\\spark-3.0.3-bin-hadoop2.7\\python\\pyspark\\broadcast.py\", line 111, in dump\n",
      "    pickle.dump(value, f, pickle_protocol)\n",
      "TypeError: cannot pickle '_thread.RLock' object\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Could not serialize broadcast: TypeError: cannot pickle '_thread.RLock' object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\apps\\opt\\spark-3.0.3-bin-hadoop2.7\\python\\pyspark\\broadcast.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(self, value, f)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m             \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPickleError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot pickle '_thread.RLock' object",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25556/2709545847.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martistAlias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\apps\\opt\\spark-3.0.3-bin-hadoop2.7\\python\\pyspark\\context.py\u001b[0m in \u001b[0;36mbroadcast\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    898\u001b[0m         \u001b[0mbe\u001b[0m \u001b[0msent\u001b[0m \u001b[0mto\u001b[0m \u001b[0meach\u001b[0m \u001b[0mcluster\u001b[0m \u001b[0monly\u001b[0m \u001b[0monce\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m         \"\"\"\n\u001b[1;32m--> 900\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mBroadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pickled_broadcast_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    901\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0maccumulator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccum_param\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\apps\\opt\\spark-3.0.3-bin-hadoop2.7\\python\\pyspark\\broadcast.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sc, value, pickle_registry, path, sock_file)\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;31m# no encryption, we can just write pickled data directly to the file from python\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[0mbroadcast_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbroadcast_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encryption_enabled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_broadcast\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitTillDataReceived\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\apps\\opt\\spark-3.0.3-bin-hadoop2.7\\python\\pyspark\\broadcast.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(self, value, f)\u001b[0m\n\u001b[0;32m    116\u001b[0m                   \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_exception_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[0mprint_exec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPicklingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPicklingError\u001b[0m: Could not serialize broadcast: TypeError: cannot pickle '_thread.RLock' object"
     ]
    }
   ],
   "source": [
    "spark.sparkContext.broadcast(artistAlias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a065f6ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25556/1273462745.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbroadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martistAlias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "broadcast(artistAlias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0758328",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25556/1614556346.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0muserArtistDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martistAlias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "userArtistDF.join(broadcast(artistAlias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe822ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d05bba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4655e767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ff6099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5af0085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d96d140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c2707f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e0eef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c370ed94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecc03e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6a3a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ded7a2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "canUserArtistDF = (userArtistDF\n",
    " .join(artistAlias, \n",
    "      on= (userArtistDF.artistid==artistAlias.badid) | (userArtistDF.artistid==artistAlias.goodid),\n",
    "      how=\"left\")\n",
    " .select(\"userid\", col(\"goodid\").alias(\"artistid\"),\"playcount\")\n",
    " #.distinct()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec8ada3",
   "metadata": {},
   "outputs": [],
   "source": [
    "canUserArtistDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c9b661",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(userArtistDF\n",
    " .alias(\"a1\")\n",
    " .join(artistAlias.alias(\"a2\"),\n",
    "       on=( (userArtistDF.artistid==artistAlias.badid) | (userArtistDF.artistid==artistAlias.goodid) ),\n",
    "       how=\"inner\")\n",
    " .select(\"userid\", col(\"goodid\").alias(\"artistid\"), \"playcount\")\n",
    " .distinct()\n",
    ").show(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5a7af45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+-----+------+------+--------+---------+\n",
      "| userid|artistid|playcount|badid|goodid|userid|artistid|playcount|\n",
      "+-------+--------+---------+-----+------+------+--------+---------+\n",
      "|1000002|       1|       55| null|  null|  null|    null|     null|\n",
      "|1000002| 1000006|       33| null|  null|  null|    null|     null|\n",
      "|1000002| 1000007|        8| null|  null|  null|    null|     null|\n",
      "|1000002| 1000009|      144| null|  null|  null|    null|     null|\n",
      "|1000002| 1000010|      314| null|  null|  null|    null|     null|\n",
      "+-------+--------+---------+-----+------+------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(userArtistDF\n",
    " .alias(\"a1\")\n",
    " .join(artistAlias.alias(\"id\"), on=[col(\"a1.artistid\")==col(\"id.badid\")], how=\"left\")\n",
    " .join(userArtistDF.alias(\"a2\"), on=col(\"a2.artistid\")==col(\"id.goodid\"), how=\"left\")\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "266c7c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|   badid|goodid|\n",
      "+--------+------+\n",
      "| 6892711|     1|\n",
      "| 6768907|     1|\n",
      "| 1330855|     1|\n",
      "| 1330866|     1|\n",
      "| 1330616|     1|\n",
      "| 1329801|     1|\n",
      "| 1178093|     1|\n",
      "| 9912772|     1|\n",
      "| 2061674|     1|\n",
      "| 2172455|     1|\n",
      "|10001148|     1|\n",
      "| 1037407|     1|\n",
      "|10285498|     1|\n",
      "| 1332568|     1|\n",
      "|10345209|     1|\n",
      "| 1010803|     1|\n",
      "| 1112830|     1|\n",
      "| 1039289|     1|\n",
      "| 1209643|     1|\n",
      "| 1125695|     1|\n",
      "+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artistAlias.filter(col(\"goodid\")==\"1\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
